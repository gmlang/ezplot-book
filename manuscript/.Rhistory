# load libraries and source functions
library(readxl)
library(tidyr)
library(dplyr)
# set paths
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "Resilience v3.0 Data.xlsx")
# read data
questions = read_excel(file_path, sheet = "Questions")
people = read_excel(file_path, sheet = "People",
col_types=c("numeric", "date", "text",
"text", "text", "text"))
results = read_excel(file_path, sheet = "Results")
# check
str(questions)
str(people)
str(results)
# merge
dat = left_join(results, people)
dat = left_join(dat, questions)
dim(dat)
str(dat)
str(dat$answer)
str(as.factor(dat$answer))
unique(dat$answer)
rm(list=ls())
# load libraries and source functions
library(readxl)
library(tidyr)
library(dplyr)
# set paths
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "Resilience v3.0 Data.xlsx")
# read data
questions = read_excel(file_path, sheet = "Questions")
people = read_excel(file_path, sheet = "People",
col_types=c("numeric", "date", "text",
"text", "text", "text"))
results = read_excel(file_path, sheet = "Results")
# check
str(questions)
str(people)
str(results)
# merge
dat = left_join(results, people)
dat = left_join(dat, questions)
dim(dat)
str(dat)
# BEGIN define functions
count_unique = function(dat) {
function(varname) length(unique(dat[[varname]]))
}
mk_freq_tbl = function(dat) {
function(varname) table(dat[[varname]])
}
count_NA = function(dat) {
function(varname) sum(is.na(dat[[varname]]))
}
# END define functions
# check NAs
missing_cnt = count_NA(dat)
NA_cnt = sapply(names(dat), function(var) missing_cnt(var))
names(NA_cnt) = names(dat)
NA_cnt
# drop NAs where it shouldn't have
dat = dat[!is.na(dat$answer),]
# check NAs again
missing_cnt = count_NA(dat)
NA_cnt = sapply(names(dat), function(var) missing_cnt(var))
names(NA_cnt) = names(dat)
NA_cnt
str(dat$answer)
unique(dat$answer)
str(factor(dat$answer, levels = lvl))
lvl = c("Rarely", "Sometimes", "Often", "Very Often", "Nearly Always")
str(factor(dat$answer, levels = lvl))
table(factor(dat$answer, levels = lvl))
dat$answer = factor(dat$answer, levels = lvl)
head(dat$answer)
head(dat$answer, 10)
# make some functions
unique_cnt = count_unique(dat)
freq_tbl = mk_freq_tbl(dat)
# num of unique people who took the survey
unique_cnt("perid")
# num of unique UniqueDiagnostic
unique_cnt("UniqueDiagnostic")
# cnt of Programtype
freq_tbl("Programtype")
# range of datecreated
summary(dat$datecreated)
# num of unique questions
unique_cnt("questionid")
unique_cnt("question")
# cnt of answer
freq_tbl("answer")
# range of dateofbirth
summary(dat$dateofbirth)
# cnt of gender, salaryband, jobfunction, country, category
freq_tbl("gender")
freq_tbl("salaryband")
freq_tbl("jobfunction")
freq_tbl("country")
freq_tbl("category")
freq_tbl("type")
freq_tbl("OptimalHealth")
freq_tbl("RatingScale")
# drop potentially useless vars
drops = c("RatingScale", "OptimalHealth", "UniqueDiagnostic",
"UniqueDiagnostic")
dat = dat[, !(names(dat) %in% drops)]
# for each person, cnt number of questions under each construct
tmp = dat %>% group_by(perid, category) %>%
summarise(num_of_qs = length(unique(questionid)))
head(tmp, 12)
summary(tmp$num_of_qs)
tmp2 = tmp %>% filter(num_of_qs < 5)
nrow(tmp2)
nrow(tmp)
# drop perid in tmp2 from dat
dat2 = dat %>% filter(!perid %in% unique(tmp2$perid))
nrow(dat) - nrow(dat2)
dat = dat2; rm(dat2)
# for each person, cnt number of questions under each construct
tmp = dat %>% group_by(perid, category) %>%
summarise(num_of_qs = length(unique(questionid)))
constructs = unique(tmp$category)
# a little function
f = function(val) {
tmp2 = tmp %>% filter(category == val)
unique(tmp2$num_of_qs)
}
sapply(constructs, f) # compare results with construct-item-cnt.png
# drop non-match perid
df1 = tmp %>% filter(category == "Spirit in Action" & num_of_qs==6)
df2 = tmp %>% filter(category == "Engage Emotion" & num_of_qs==5)
dat1 = dat %>% filter(!perid %in% unique(c(df1$perid, df2$perid)))
nrow(dat) - nrow(dat1)
# cnt number of questions under each construct in dat1
dat1 %>% group_by(category) %>%
summarise(num_of_qs = length(unique(questionid)))
# note: now, the results match exactly with construct-item-cnt.png
# creat a flag to indicate to exclude the unique perid in df1 and df2 when
# calculating cronbach for "Spirit in Action" and "Engage Emotion"
dat$flag_spirit_in_action = replicate(nrow(dat), 1)
dat$flag_spirit_in_action[dat$perid %in% unique(df1$perid)] = 0
dat$flag_engage_emotion = replicate(nrow(dat), 1)
dat$flag_engage_emotion[dat$perid %in% unique(df2$perid)] = 0
# sanity check
stopifnot(length(unique(dat$perid[dat$flag_spirit_in_action == 0])) == nrow(df1))
stopifnot(length(unique(dat$perid[dat$flag_engage_emotion == 0])) == nrow(df2))
# save
outpath = file.path(data_path, "cleaned")
dir.create(outpath, showWarnings = F)
save(dat, file=file.path(outpath, "dat.rda"))
dat$answer[1]
dat$answer[1] + dat$answer[2]
rm(list=ls())
# load libraries and source functions
library(readxl)
library(tidyr)
library(dplyr)
# set paths
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "Resilience v3.0 Data.xlsx")
# read data
questions = read_excel(file_path, sheet = "Questions")
people = read_excel(file_path, sheet = "People",
col_types=c("numeric", "date", "text",
"text", "text", "text"))
results = read_excel(file_path, sheet = "Results")
# check
str(questions)
str(people)
str(results)
# merge
dat = left_join(results, people)
dat = left_join(dat, questions)
dim(dat)
str(dat)
# BEGIN define functions
count_unique = function(dat) {
function(varname) length(unique(dat[[varname]]))
}
mk_freq_tbl = function(dat) {
function(varname) table(dat[[varname]])
}
count_NA = function(dat) {
function(varname) sum(is.na(dat[[varname]]))
}
# END define functions
# check NAs
missing_cnt = count_NA(dat)
NA_cnt = sapply(names(dat), function(var) missing_cnt(var))
names(NA_cnt) = names(dat)
NA_cnt
# drop NAs where it shouldn't have
dat = dat[!is.na(dat$answer),]
# check NAs again
missing_cnt = count_NA(dat)
NA_cnt = sapply(names(dat), function(var) missing_cnt(var))
names(NA_cnt) = names(dat)
NA_cnt
# # change answer to factor
# str(dat$answer)
# unique(dat$answer)
# lvl = c("Rarely", "Sometimes", "Often", "Very Often", "Nearly Always")
# dat$answer = factor(dat$answer, levels = lvl)
# head(dat$answer, 10)
# add a score column
dat$score[dat$answer == "Rarely"] = 1
dat$score[dat$answer == "Sometimes"] = 2
dat$score[dat$answer == "Often"] = 3
dat$score[dat$answer == "Very Often"] = 4
dat$score[dat$answer == "Nearly Always"] = 5
# make some functions
unique_cnt = count_unique(dat)
freq_tbl = mk_freq_tbl(dat)
# num of unique people who took the survey
unique_cnt("perid")
# num of unique UniqueDiagnostic
unique_cnt("UniqueDiagnostic")
# cnt of Programtype
freq_tbl("Programtype")
# range of datecreated
summary(dat$datecreated)
# num of unique questions
unique_cnt("questionid")
unique_cnt("question")
# cnt of answer
freq_tbl("answer")
# range of dateofbirth
summary(dat$dateofbirth)
# cnt of gender, salaryband, jobfunction, country, category
freq_tbl("gender")
freq_tbl("salaryband")
freq_tbl("jobfunction")
freq_tbl("country")
freq_tbl("category")
freq_tbl("type")
freq_tbl("OptimalHealth")
freq_tbl("RatingScale")
# drop potentially useless vars
drops = c("RatingScale", "OptimalHealth", "UniqueDiagnostic",
"UniqueDiagnostic")
dat = dat[, !(names(dat) %in% drops)]
# for each person, cnt number of questions under each construct
tmp = dat %>% group_by(perid, category) %>%
summarise(num_of_qs = length(unique(questionid)))
head(tmp, 12)
summary(tmp$num_of_qs)
tmp2 = tmp %>% filter(num_of_qs < 5)
nrow(tmp2)
nrow(tmp)
# drop perid in tmp2 from dat
dat2 = dat %>% filter(!perid %in% unique(tmp2$perid))
nrow(dat) - nrow(dat2)
dat = dat2; rm(dat2)
# for each person, cnt number of questions under each construct
tmp = dat %>% group_by(perid, category) %>%
summarise(num_of_qs = length(unique(questionid)))
constructs = unique(tmp$category)
# a little function
f = function(val) {
tmp2 = tmp %>% filter(category == val)
unique(tmp2$num_of_qs)
}
sapply(constructs, f) # compare results with construct-item-cnt.png
# drop non-match perid
df1 = tmp %>% filter(category == "Spirit in Action" & num_of_qs==6)
df2 = tmp %>% filter(category == "Engage Emotion" & num_of_qs==5)
dat1 = dat %>% filter(!perid %in% unique(c(df1$perid, df2$perid)))
nrow(dat) - nrow(dat1)
# cnt number of questions under each construct in dat1
dat1 %>% group_by(category) %>%
summarise(num_of_qs = length(unique(questionid)))
# note: now, the results match exactly with construct-item-cnt.png
# creat a flag to indicate to exclude the unique perid in df1 and df2 when
# calculating cronbach for "Spirit in Action" and "Engage Emotion"
dat$flag_spirit_in_action = replicate(nrow(dat), 1)
dat$flag_spirit_in_action[dat$perid %in% unique(df1$perid)] = 0
dat$flag_engage_emotion = replicate(nrow(dat), 1)
dat$flag_engage_emotion[dat$perid %in% unique(df2$perid)] = 0
# sanity check
stopifnot(length(unique(dat$perid[dat$flag_spirit_in_action == 0])) == nrow(df1))
stopifnot(length(unique(dat$perid[dat$flag_engage_emotion == 0])) == nrow(df2))
# save
outpath = file.path(data_path, "cleaned")
dir.create(outpath, showWarnings = F)
save(dat, file=file.path(outpath, "dat.rda"))
36 * 10^6 * 2 * 8 / (2^20)
rm(list=ls())
library(tidyr)
library(dplyr)
# set paths and load data
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "cleaned/dat.rda")
load(file_path)
dim(dat)
########## BEGIN Sanity Check ########
# for each person, cnt number of questions under each construct
tmp = dat %>% filter(flag_spirit_in_action==1 & flag_engage_emotion==1) %>%
group_by(perid, category) %>%
summarise(num_of_qs = length(unique(questionid)))
constructs = unique(tmp$category)
# a little function
f = function(val) {
tmp2 = tmp %>% filter(category == val)
unique(tmp2$num_of_qs)
}
sapply(constructs, f) # compare results with construct-item-cnt.png
########## END Sanity Check ########
head(tmp, 12)
library(psy)
library(psych)
datafilename="http://personality-project.org/R/datasets/extraversion.items.txt"
items=read.table(datafilename,header=TRUE)                    #read the data
datafilename="http://personality-project.org/r/datasets/extraversion.items.txt"
items=read.table(datafilename, header=TRUE)
str(items)
attach(items)         #make this the active path
E1=q_262 -q_1480 +q_819 -q_1180 +q_1742  +14
E1.df = data.frame(q_262 ,q_1480 ,q_819 ,q_1180 ,q_1742 ) #put these items into a data frame
summary(E1.df)                             #give summary statistics for these items
round(cor(E1.df,use="pair"),2)             #correlate the 5 items, rounded off to 2 decimals,
round(cor(E1.df,E1,use="pair"),2)          #show the item by scale correlations
alpha.scale=function (x,y)   #create a reusable function to find coefficient alpha
#input to the function are a scale and a data.frame of the items in the scale
{
Vi=sum(diag(var(y,na.rm=TRUE)))     #sum of item variance
Vt=var(x,na.rm=TRUE)                #total test variance
n=dim(y)[2]     #how many items are in the scale?  (calculated dynamically)
((Vt-Vi)/Vt)*(n/(n-1))}             #alpha
E.alpha=alpha.scale(E1,E1.df)
detach(items)
E.alpha
rm(list=ls())
# load libraries and source functions
library(tidyr)
library(dplyr)
# set paths and load data
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "cleaned/dat.rda")
load(file_path)
dim(dat)
table(dat$category)
lst_of_dfs = split(dat, dat$category)
head(lst_of_dfs[[1]])
tmp = lst_of_dfs[[1]]
table(tmp$category)
table(tmp$question)
rm(list=ls())
# load libraries and source functions
library(tidyr)
library(dplyr)
# set paths and load data
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "cleaned/dat.rda")
load(file_path)
dim(dat)
# get the data
datafilename="http://personality-project.org/r/datasets/extraversion.items.txt"
items=read.table(datafilename, header=TRUE)
str(items)
str(tmp)
str(tmp)
tmp = lst_of_dfs[[1]]
str(tmp)
lst_of_dfs = split(dat, dat$category)
tmp = lst_of_dfs[[1]]
str(tmp)
names(lst_of_dfs)
names(lst_of_dfs)[[1]]
construct = names(lst_of_dfs)[[1]]
tolower(construct)
construct = names(lst_of_dfs)[[6]]
tolower(construct)
paste(tolower(construct), "")
paste(tolower(construct), collapse = "")
paste(tolower(construct), collapse = " ")
gsub(" ", "_", tolower(construct))
tmp = lst_of_dfs[[1]]
construct = names(lst_of_dfs)[[6]]
if (construct == "Spirit in Action") {
tmp = tmp %>% filter(flag_spirit_in_action == 1) %>%
select(perid, type, question, questionid, answer, score)
} else if (construct == "Engage Emotion") {
tmp = tmp %>% filter(flag_engage_emotion == 1) %>%
select(perid, type, question, questionid, answer, score)
} else {
tmp = tmp %>% select(perid, type, question, questionid, answer, score)
}
filename = paste0(gsub(" ", "_", tolower(construct)), ".rda")
filename
str(tmp)
tmp = lst_of_dfs[[1]]
construct = names(lst_of_dfs)[[6]]
if (construct == "Spirit in Action") {
tmp = tmp %>% filter(flag_spirit_in_action == 1) %>%
select(perid, question, questionid, answer, score)
} else if (construct == "Engage Emotion") {
tmp = tmp %>% filter(flag_engage_emotion == 1) %>%
select(perid, question, questionid, answer, score)
} else {
tmp = tmp %>% select(perid, question, questionid, answer, score)
}
tmp = lst_of_dfs[[1]]
construct = names(lst_of_dfs)[[1]]
if (construct == "Spirit in Action") {
tmp = tmp %>% filter(flag_spirit_in_action == 1) %>%
select(perid, question, questionid, answer, score)
} else if (construct == "Engage Emotion") {
tmp = tmp %>% filter(flag_engage_emotion == 1) %>%
select(perid, question, questionid, answer, score)
} else {
tmp = tmp %>% select(perid, question, questionid, answer, score)
}
filename = paste0(gsub(" ", "_", tolower(construct)), ".rda")
str(tmp)
rm(list=ls())
# load libraries and source functions
library(tidyr)
library(dplyr)
# set paths and load data
proj_path = "~/Projects/ds/sven"
data_path = file.path(proj_path, "data")
file_path = file.path(data_path, "cleaned/dat.rda")
load(file_path)
dim(dat)
lst_of_dfs = split(dat, dat$category)
tmp = lst_of_dfs[[1]]
construct = names(lst_of_dfs)[[1]]
if (construct == "Spirit in Action") {
tmp = tmp %>% filter(flag_spirit_in_action == 1) %>%
select(perid, question, questionid, answer, score)
} else if (construct == "Engage Emotion") {
tmp = tmp %>% filter(flag_engage_emotion == 1) %>%
select(perid, question, questionid, answer, score)
} else {
tmp = tmp %>% select(perid, question, questionid, answer, score)
}
filename = paste0(gsub(" ", "_", tolower(construct)), ".rda")
str(tmp)
tmp = lst_of_dfs[[1]]
construct = names(lst_of_dfs)[[1]]
if (construct == "Spirit in Action") {
tmp = tmp %>% filter(flag_spirit_in_action == 1) %>%
select(question, questionid, answer, score)
} else if (construct == "Engage Emotion") {
tmp = tmp %>% filter(flag_engage_emotion == 1) %>%
select(question, questionid, answer, score)
} else {
tmp = tmp %>% select(question, questionid, answer, score)
}
filename = paste0(gsub(" ", "_", tolower(construct)), ".rda")
str(tmp)
filename
out = file.path(proj_path, filename)
out
rm(list=ls())
# load libraries and source functions
library(tidyr)
library(dplyr)
# set paths and load data
proj_path = "~/Projects/ds/sven"
cleaned_path = file.path(proj_path, "data/cleaned")
file_path = file.path(cleaned_path, "dat.rda")
load(file_path)
dim(dat)
lst_of_dfs = split(dat, dat$category)
tmp = lst_of_dfs[[1]]
construct = names(lst_of_dfs)[[1]]
if (construct == "Spirit in Action") {
tmp = tmp %>% filter(flag_spirit_in_action == 1) %>%
select(question, questionid, answer, score)
} else if (construct == "Engage Emotion") {
tmp = tmp %>% filter(flag_engage_emotion == 1) %>%
select(question, questionid, answer, score)
} else {
tmp = tmp %>% select(question, questionid, answer, score)
}
filename = paste0(gsub(" ", "_", tolower(construct)), ".rda")
out = file.path(proj_path, filename)
out
out = file.path(cleaned_path, filename)
out
lst_of_dfs = split(dat, dat$category)
save_data_by_cat = function(i) {
df = lst_of_dfs[[i]]
construct = names(lst_of_dfs)[[i]]
if (construct == "Spirit in Action")
df = df %>% filter(flag_spirit_in_action == 1) %>%
select(question, questionid, answer, score)
else if (construct == "Engage Emotion")
df = df %>% filter(flag_engage_emotion == 1) %>%
select(question, questionid, answer, score)
else df = df %>% select(question, questionid, answer, score)
# save
filename = paste0(gsub(" ", "_", tolower(construct)), ".rda")
save(df, file = file.path(cleaned_path, filename))
}
lapply(1:length(lst_of_dfs), save_data_by_cat)
# get the data
datafilename="http://personality-project.org/r/datasets/extraversion.items.txt"
items=read.table(datafilename, header=TRUE)
str(items)
